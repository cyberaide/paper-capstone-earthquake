@misc{www-singularity,
	title = {{Singularity}},
	author = {{Sylabs}},
	year = 2022,
	month = jan,
	url = {https://sylabs.io},
	howpublished = {Web Page}
}

@misc{fox2021earthquake,
  title =	 {Earthquake Nowcasting with Deep Learning},
  author =	 {Geoffrey Fox and John Rundle and Andrea Donnellan
                  and Bo Feng},
  year =	 2021,
  eprint =	 {2201.01869},
  archivePrefix ={arXiv},
  primaryClass = {physics.geo-ph}
}

%% TODO: Fix this entry to use the IEEE paper once published
@online{fox2022aiforscience,
  author =	 {Geoffrey Fox and John Rundle and Bo Feng},
  title =	 {{AI for Science illustrated by Deep Learning for
                  Geospatial Time Series}},
  booktitle = {IEEE 12th Annual Computing and Communication
                  Workshop and Conference},
  year =	 2022,
  month =	 jan,
  organization = {Digital Science Center},
  publisher =	 {IEEE},
  series =	 {CCWC},
  url =
                  {https://docs.google.com/presentation/d/1UiMVV4mMzIXIzBJ2WqFrWnqVI6NaI0jevb7BKulun2c/edit?usp=sharing},
  note = {improve}
}

@misc{las-intro-python,
  author =	 {von Laszewski, Gregor},
  title =	 {Introduction to Python},
  howpublished = {Online Book},
  year =	 2022,
  month =	 jan,
  url =
                  {https://cloudmesh-community.github.io/pub/vonLaszewski-python.pdf}
}

@misc{vaswani2017attention,
  title =	 {Attention Is All You Need},
  author =	 {Ashish Vaswani and Noam Shazeer and Niki Parmar and
                  Jakob Uszkoreit and Llion Jones and Aidan N. Gomez
                  and Lukasz Kaiser and Illia Polosukhin},
  year =	 2017,
  eprint =	 {1706.03762},
  archivePrefix ={arXiv},
  primaryClass = {cs.CL}
}

@misc{www-aurora,
  title =	 {Aurora},
  author =   {Argonne Leadership Computing Facility},
  year =	 2022,
  month =	 jan,
  url =		 {https://www.alcf.anl.gov/aurora},
  howpublished = {Web Page}
}

@misc{www-conda,
  title =	 {{Conda}},
  author =	 {{Conda Developers}},
  year =	 2022,
  month =	 jan,
  url =		 {https://docs.conda.io/en/latest},
  howpublished = {Web Page}
}

@misc{www-dgx-station-a100,
  title =	 {{NVIDIA DGX Station A100}},
  author =	 {{NVIDIA}},
  year =	 2022,
  month =	 jan,
  url =
                  {https://www.nvidia.com/en-us/data-center/dgx-station-a100},
  howpublished = {Web Page}
}

@misc{www-expanse,
  title =	 {{Expanse}},
  author = {San Diego Supercomputer Center},
  year =	 2022,
  month =	 jan,
  url =      {https://www.sdsc.edu/services/hpc/expanse/index.html},
  howpublished = {Web Page}
}

@Misc{www-horovod,
  author =	 {{Horovod Developers}},
  howpublished = {Web Page},
  month =	 jan,
  title =	 {{Horovod}},
  year =	 2022,
  abstract =	 {Horovod is a distributed deep learning training
                  framework for TensorFlow, Keras, PyTorch, and Apache
                  MXNet. The goal of Horovod is to make distributed
                  deep learning fast and easy to use.},
  journal =	 {GitHub},
  url =		 {https://github.com/horovod/horovod},
}

@Misc{www-jabrefg-org,
  author =	 {{jabref.org}},
  howpublished = {Web Page},
  month =	 jan,
  title =	 {{JabRef}},
  year =	 2022,
  url =		 {https://jabref.org},
}

@misc{www-jupyterlab,
  author =	 {{Project Jupyter}},
  title =	 {Jupyterlab (version ?)},
  year =	 2022,
  url =		 {https://jupyter.org},
  howpublished = {Web Page}
}

@misc{www-mlcommons,
  author =	 {{MLCommons}},
  title =	 {MLCommons},
  year =	 2022,
  url =		 {https://mlcommons.org/},
  howpublished = {Web Page}
}

@misc{www-mlcommons-science,
  author =	 {MLCommons Science Working Group},
  title =	 {Science Working Group | MLCommons },
  year =	 2022,
  url =		 {https://mlcommons.org/en/groups/research-science/},
  howpublished = {Web Page}
}

%% TODO: Reivew this entry; seems wrong
@Misc{www-mlcommons-eathquake,
  author =	 {Geoffery Fox and Gregor von Laszewski},
  howpublished = {Web Page},
  title =	 {{MLCommons Earthquake Science Benchmark}},
  year =	 2013,
  journal =	 {GitHub Repository},
  publisher =	 {GitHub},
  url = {https://github.com/Data-ScienceHub/mlcommons-science},
}

@misc{www-mlcube,
  author =	 {{MLCommons}},
  title =	 {MLCube},
  howpublished = {Web Page},
  year =	 2022,
  month =	 jan,
  url =		 {https://mlcommons.org/en/mlcube/},
  abstract =	 {MLCube is a set of common conventions for creating
                  ML software that can "plug-and-play" on many
                  different systems. MLCube makes it easier for
                  researchers to share innovative ML models, for a
                  developer to experiment with many different models,
                  and for software companies to create infrastructure
                  for models. It creates opportunities by putting ML
                  in the hands of more people.},
}

@Misc{www-modules,
  author =	 {{Lmod Developers}},
  howpublished = {Web Page},
  month =	 jan,
  title =	 {{Lmod: A New Environment Module System}},
  year =	 2022,
  url =		 {https://lmod.readthedocs.io/en/latest},
}

@Misc{www-onnen2021,
  author =	 {Onnen, Heiko},
  howpublished = {Blog},
  month =	 dec,
  title =	 {{Temporal Fusion Transformer: A Primer on deep
                  forecasting in python}},
  year =	 2021,
  publisher =	 {Towards Data Science},
  url =
                  {https://towardsdatascience.com/temporal-fusion-transformer-a-primer-on-deep-forecasting-in-python-4eb37f3f3594},
}

@misc{www-papermill,
  title =	 {{Papermill 2.3.4 documentation}},
  author =	 {{Papermill Developers}},
  year =	 2022,
  month =	 jan,
  url =		 {https://papermill.readthedocs.io/en/latest},
  howbublished = {Web Page}
}

@misc{www-pearl-1,
  title =	 {{SCD Introducing the small, yet powerful, PEARL
                  system for AI and Machine Learning}},
  year =	 2022,
  month =	 jan,
  author =	 {{Rutherford Appleton Laboratory}},
  url =
                  {https://www.scd.stfc.ac.uk/Pages/Introducing-the-PEARL-system-for-AI-and-Machine-Learning.aspx},
  howpublished = {Web Page}
}

@misc{www-perlmutter,
  title =	 {{Perlmutter}},
  author =	 {National Energy Research Scientific Computing Center},
  url =		 {https://www.nersc.gov/systems/perlmutter},
  year =	 2022,
  month =	 jan,
  howpublished = {Web Page}
}

@misc{www-pytorch,
  title =	 {{PyTorch}},
  author =   {{Facebook AI Research Lab} and {PyTorch Community}},
  year =	 2022,
  month =	 jan,
  url =		 {https://pytorch.org},
  howpublished = {Web Page}
}

@InProceedings{pytorch-paper,
  author =	 {Paszke, Adam and Gross, Sam and Massa, Francisco and
                  Lerer, Adam and Bradbury, James and Chanan, Gregory
                  and Killeen, Trevor and Lin, Zeming and Gimelshein,
                  Natalia and Antiga, Luca and Desmaison, Alban and
                  Kopf, Andreas and Yang, Edward and DeVito, Zachary
                  and Raison, Martin and Tejani, Alykhan and
                  Chilamkurthy, Sasank and Steiner, Benoit and Fang,
                  Lu and Bai, Junjie and Chintala, Soumith},
  title =	 {PyTorch: An Imperative Style, High-Performance Deep
                  Learning Library},
  booktitle =	 {33rd Conference on Neural Information Processing
                  Systems (NeurIPS 2019)},
  editor =	 {H. Wallach and H. Larochelle and A. Beygelzimer and
                  F. d\textquotesingle Alch\'{e}-Buc and E. Fox and
                  R. Garnett},
  address =	 {Vancouver, Canada},
  publisher =	 {TODO: ??? Curran Associates, Inc.},
  abstract =	 {Deep learning frameworks have often focused on
                  either usability or speed, but not both. PyTorch is
                  a machine learning library that shows that these two
                  goals are in fact compatible: it provides an
                  imperative and Pythonic programming style that
                  supports code as a model, makes debugging easy and
                  is consistent with other popular scientific
                  computing libraries, while remaining efficient and
                  supporting hardware accelerators such as GPUs.  In
                  this paper, we detail the principles that drove the
                  implementation of PyTorch and how they are reflected
                  in its architecture. We emphasize that every aspect
                  of PyTorch is a regular Python program under the
                  full control of its user. We also explain how the
                  careful and pragmatic implementation of the key
                  components of its runtime enables them to work
                  together to achieve compelling performance. We
                  demonstrate the efficiency of individual subsystems,
                  as well as the overall speed of PyTorch on several
                  common benchmarks.},
  url =
                  {http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf},
  year =	 2019,
  month =	 jan,
}

@misc{www-rivanna,
  title =	 {{Rivanna}},
  author =   {Univerity of Virginia Research Computing},
  year =	 2022,
  month =	 jan,
  url =      {https://www.rc.virginia.edu/userinfo/rivanna/overview},
  howpublished = {Web Page}
}

@misc{www-summit,
  title =	 {{Summit}},
  author =	 {Oak Ridge Leadership Computing Facility},
  year =	 2022,
  month =	 jan,
  url =		 {https://www.olcf.ornl.gov/summit},
  howpublished = {Web Page}
}

@article{www-murakami2021,
   author={Murakami, Sota and Ichimura, Tsuyoshi and Fujita, Kohei and Hori, Takane and Ohta, Yusaku},   
   title={Sensitivity Analysis for Seafloor Geodetic Constraints on Coseismic Slip and Interseismic Slip-Deficit Distributions},      
   journal={Frontiers in Earth Science},      
   volume={9},      
   year={2021},
   month={April},
   url={https://www.frontiersin.org/article/10.3389/feart.2021.614088},       
   doi={10.3389/feart.2021.614088},      
   issn={2296-6463},
   pages={1--13},
   abstract={Estimating the coseismic slip distribution and interseismic slip-deficit distribution play an important role in understanding the mechanism of massive earthquakes and predicting the resulting damage. It is useful to observe the crustal deformation not only in the land area, but also directly above the seismogenic zone. Therefore, improvements in terms of measurement precision and increase in the number of observation points have been proposed in various forms of seafloor observation. However, there is lack of research on the quantitative evaluation of the estimation accuracy in cases where new crustal deformation observation points are available or when the precision of the observation methods have been improved. On the other hand, the crustal structure models are improving and finite element analysis using these highly detailed crustal structure models is becoming possible. As such, there is the real possibility of performing an inverted slip estimation with high accuracy via numerical experiments. In view of this, in this study, we proposed a method for quantitatively evaluating the improvement in the estimation accuracy of the coseismic slip distribution and the interseismic slip-deficit distribution in cases where new crustal deformation observation points are available or where the precision of the observation methods have been improved. As a demonstration, a quantitative evaluation was performed using an actual crustal structure model and observation point arrangement. For the target area, we selected the Kuril Trench off Tokachi and Nemuro, where M9-class earthquakes have been known to occur in the past and where the next imminent earthquake is anticipated. To appropriately handle the effects of the topography and plate boundary geometry, a highly detailed three-dimensional finite element model was constructed and Green’s functions of crustal deformation were calculated with high accuracy. By performing many inversions via optimization using Green’s functions, we statistically evaluated the effect of increase in the number of observation points of the seafloor crustal deformation measurement and the influence of measurement error, taking into consideration the diversity of measurement errors. As a result, it was demonstrated that the observation of seafloor crustal deformation near the trench axis plays an extremely important role in the estimation performance.}
}
@article{cheong1997optimizer,
  title={An optimizer for multimedia instruction sets},
  author={Cheong, Gerald and Lam, Monica},
  journal={Contract},
  volume={30602},
  number={95-C},
  pages={0098},
  year={1997},
  publisher={Citeseer},
  url={https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.36.9750}
}

@misc{mattson2019mlperf,
    title={MLPerf Training Benchmark},
    author={Peter Mattson and Christine Cheng and Cody Coleman and Greg Diamos and Paulius Micikevicius and David Patterson and Hanlin Tang and Gu-Yeon Wei and Peter Bailis and Victor Bittorf and David Brooks and Dehao Chen and Debojyoti Dutta and Udit Gupta and Kim Hazelwood and Andrew Hock and Xinyuan Huang and Atsushi Ike and Bill Jia and Daniel Kang and David Kanter and Naveen Kumar and Jeffery Liao and Guokai Ma and Deepak Narayanan and Tayo Oguntebi and Gennady Pekhimenko and Lillian Pentecost and Vijay Janapa Reddi and Taylor Robie and Tom St. John and Tsuguchika Tabaru and Carole-Jean Wu and Lingjie Xu and Masafumi Yamazaki and Cliff Young and Matei Zaharia},
    year={2019},
    eprint={1910.01500},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@article{Saito2004,
    title = {The earth simulator: Roles and impacts},
    journal = {Nuclear Physics B - Proceedings Supplements},
    volume = {129-130},
    pages = {102-108},
    year = {2004},
    note = {Lattice 2003},
    issn = {0920-5632},
    doi = {https://doi.org/10.1016/S0920-5632(03)02511-8},
    url = {https://www.sciencedirect.com/science/article/pii/S0920563203025118},
    author = {Tetsuya Sato},
    abstract = {In the first place, the architecture and performance of the Earth Simulator and the managing system of the Earth Simulator Center are briefly described. Secondly, some examples of products obtained so far by ES are presented to demonstrate its actual power. Then, a holistic simulator concept that should be the next generation simulator is described, and lastly the paradigm shift in science, manufacturing and human thought that could be brought by the holistic simulator is mentioned [1–3].}
}